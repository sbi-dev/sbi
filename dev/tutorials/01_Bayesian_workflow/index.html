
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://sbi-dev.github.io/sbi/dev/tutorials/01_Bayesian_workflow/">
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.18">
    
    
      
        <title>The Bayesian workflow in sbi - sbi</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
      
      
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M1%207.775V2.75C1%201.784%201.784%201%202.75%201h5.025c.464%200%20.91.184%201.238.513l6.25%206.25a1.75%201.75%200%200%201%200%202.474l-5.026%205.026a1.75%201.75%200%200%201-2.474%200l-6.25-6.25A1.75%201.75%200%200%201%201%207.775m1.5%200c0%20.066.026.13.073.177l6.25%206.25a.25.25%200%200%200%20.354%200l5.025-5.025a.25.25%200%200%200%200-.354l-6.25-6.25a.25.25%200%200%200-.177-.073H2.75a.25.25%200%200%200-.25.25ZM6%205a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../static/global.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#the-bayesian-workflow-in-sbi" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="sbi" class="md-header__button md-logo" aria-label="sbi" data-md-component="logo">
      
  <img src="../../static/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            sbi
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              The Bayesian workflow in sbi
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="http://github.com/sbi-dev/sbi" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    sbi-dev/sbi
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="sbi" class="md-nav__button md-logo" aria-label="sbi" data-md-component="logo">
      
  <img src="../../static/logo.svg" alt="logo">

    </a>
    sbi
  </label>
  
    <div class="md-nav__source">
      <a href="http://github.com/sbi-dev/sbi" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    sbi-dev/sbi
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tutorials and Examples
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FAQ
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Contributing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contribute/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    How to contribute
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../code_of_conduct/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Code of Conduct
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../citation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Citation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../credits/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Credits
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#defining-the-simulator-and-prior" class="md-nav__link">
    <span class="md-ellipsis">
      Defining the simulator and prior
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generating-the-training-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Generating the training dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setting-up-the-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      Setting up the neural network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inferring-the-posterior" class="md-nav__link">
    <span class="md-ellipsis">
      Inferring the posterior
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#visualizing-the-posterior" class="md-nav__link">
    <span class="md-ellipsis">
      Visualizing the posterior
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#diagnosing-potential-issues-in-the-posterior" class="md-nav__link">
    <span class="md-ellipsis">
      Diagnosing potential issues in the posterior
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Diagnosing potential issues in the posterior">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#posterior-predictive-checks" class="md-nav__link">
    <span class="md-ellipsis">
      Posterior predictive checks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#simulation-based-calibration" class="md-nav__link">
    <span class="md-ellipsis">
      Simulation-based calibration
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Next steps
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="the-bayesian-workflow-in-sbi">The Bayesian workflow in <code>sbi</code><a class="headerlink" href="#the-bayesian-workflow-in-sbi" title="Permanent link">&para;</a></h1>
<p>In this tutorial, we will perform a full Bayesian workflow with <code>sbi</code> using the Lotka-Volterra simulator.  </p>
<p>Here is a code-snippet that you will learn to understand:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sbi.neural_nets</span><span class="w"> </span><span class="kn">import</span> <span class="n">posterior_nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sbi.inference</span><span class="w"> </span><span class="kn">import</span> <span class="n">NPE</span><span class="p">,</span> <span class="n">DirectPosterior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sbi.diagnostics</span><span class="w"> </span><span class="kn">import</span> <span class="n">SBC</span>

<span class="n">num_simulations</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">num_simulations</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">simulate</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

<span class="c1"># Train neural network.</span>
<span class="n">inference</span> <span class="o">=</span> <span class="n">NPE</span><span class="p">(</span><span class="n">prior</span><span class="p">)</span>
<span class="n">posterior_net</span> <span class="o">=</span> <span class="n">inference</span><span class="o">.</span><span class="n">append_simulations</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">inference</span><span class="o">.</span><span class="n">build_posterior</span><span class="p">()</span>

<span class="c1"># Diagnostics with SBC.</span>
<span class="n">thetas</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">num_sbc_samples</span><span class="p">,))</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">simulator</span><span class="p">(</span><span class="n">thetas</span><span class="p">)</span>
<span class="n">ranks</span><span class="p">,</span> <span class="n">dap_samples</span> <span class="o">=</span> <span class="n">run_sbc</span><span class="p">(</span>
    <span class="n">thetas</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">posterior</span><span class="p">,</span> <span class="n">num_posterior_samples</span><span class="o">=</span><span class="mi">1_000</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>
<p>Let&rsquo;s get started!</p>
<h2 id="defining-the-simulator-and-prior">Defining the simulator and prior<a class="headerlink" href="#defining-the-simulator-and-prior" title="Permanent link">&para;</a></h2>
<p>In this example, we will use the Lotka-Volterra simulator. This simulator models the population of prey and predator, given four parameters:</p>
<ul>
<li><span class="arithmatex">\(\alpha\)</span>: Prey birth rate: The rate at which prey reproduce in the absence of predators</li>
<li><span class="arithmatex">\(\beta\)</span>: Predation rate: The rate at which predators consume prey, reducing the prey population</li>
<li><span class="arithmatex">\(\delta\)</span>: Predator reproduction rate: The rate at which predators reproduce based on prey consumption</li>
<li><span class="arithmatex">\(\gamma\)</span>: Predator death rate: The rate at which predators die in the absence of prey</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">lotka_volterra</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
    <span class="n">prey</span><span class="p">,</span> <span class="n">predator</span> <span class="o">=</span> <span class="n">y</span>
    <span class="n">dprey_dt</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">prey</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">prey</span> <span class="o">*</span> <span class="n">predator</span>
    <span class="n">dpredator_dt</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">prey</span> <span class="o">*</span> <span class="n">predator</span> <span class="o">-</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">predator</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">dprey_dt</span><span class="p">,</span> <span class="n">dpredator_dt</span><span class="p">])</span>

<span class="k">def</span><span class="w"> </span><span class="nf">simulate</span><span class="p">(</span><span class="n">parameters</span><span class="p">):</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

    <span class="n">y0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">40.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">])</span>  <span class="c1"># Initial populations</span>
    <span class="n">t_span</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># Total simulation time</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Time step</span>

    <span class="n">timesteps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">t_span</span> <span class="o">/</span> <span class="n">dt</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">timesteps</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">lotka_volterra</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">)</span> <span class="o">*</span> <span class="n">dt</span>

    <span class="k">return</span> <span class="n">y</span>
</code></pre></div>
<p>Let&rsquo;s inspect this simulator a set of example parameters:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">time_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">observation</span> <span class="o">=</span> <span class="n">simulate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_vec</span><span class="p">,</span> <span class="n">observation</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Prey&quot;</span><span class="p">,</span> <span class="s2">&quot;Predator&quot;</span><span class="p">])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Population&quot;</span><span class="p">)</span>
</code></pre></div>
<p><img alt="png" src="../01_Bayesian_workflow_files/01_Bayesian_workflow_7_0.png" /></p>
<p>Typically, we will not be able to observe populations exactly, but only with noise. In addition, in this example, we will aim to reproduce summary statistics of these simulations. Let&rsquo;s add noise and define these statistics:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">summarize_simulation</span><span class="p">(</span><span class="n">simulation_result</span><span class="p">):</span>
    <span class="n">observation_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2000</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">noisy_sim</span> <span class="o">=</span> <span class="n">simulation_result</span> <span class="o">+</span> <span class="n">observation_noise</span>

    <span class="n">prey_population</span> <span class="o">=</span> <span class="n">noisy_sim</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">predator_population</span> <span class="o">=</span> <span class="n">noisy_sim</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">summary</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">prey_population</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">predator_population</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">prey_population</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predator_population</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
</code></pre></div>
<blockquote>
<p><code>sbi</code> can also perform inference given the raw time series with an <em>embedding network</em>. This is described in <a href="">this how-to guide</a>.</p>
</blockquote>
<p>Let&rsquo;s define a prior over the four parameters. In this case, we assume a uniform prior:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sbi.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">BoxUniform</span>

<span class="n">lower_bound</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">])</span>
<span class="n">upper_bound</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">])</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">BoxUniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">lower_bound</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">upper_bound</span><span class="p">)</span>
</code></pre></div>
<h2 id="generating-the-training-dataset">Generating the training dataset<a class="headerlink" href="#generating-the-training-dataset" title="Permanent link">&para;</a></h2>
<p>Using the prior and the simulator, we can generate simulated data. We first generate prior samples:</p>
<div class="highlight"><pre><span></span><code><span class="n">theta</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">10_000</span><span class="p">,))</span>
</code></pre></div>
<p>As before, you can run simulations offline (e.g. on a cluster). For this example, we parallelize simulations via <code>joblib</code>. We define a small helper to run simulations in parallel:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">joblib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>


<span class="k">def</span><span class="w"> </span><span class="nf">parallel_simulate</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
    <span class="c1"># Our simulator uses numpy, but prior samples are in PyTorch.</span>
    <span class="n">theta_np</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">simulation_outputs</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)(</span>
        <span class="n">delayed</span><span class="p">(</span><span class="n">simulate</span><span class="p">)(</span><span class="n">batch</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">theta_np</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">simulation_outputs</span><span class="p">)</span>
</code></pre></div>
<p>And we can run the simulations:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># This takes a few seconds.</span>
<span class="n">simulation_outputs</span> <span class="o">=</span> <span class="n">parallel_simulate</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">summarize_simulation</span><span class="p">(</span><span class="n">sim</span><span class="p">)</span> <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">simulation_outputs</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta.shape&quot;</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x.shape&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>theta.shape torch.Size([10000, 4])
x.shape torch.Size([10000, 4])
</code></pre></div>

<p>Having generated this dataset, we recommend that you briefly check whether the simulations roughly cover the observation. Let&rsquo;s first compute the summary statistics of the observation:</p>
<div class="highlight"><pre><span></span><code><span class="n">x_obs</span> <span class="o">=</span> <span class="n">summarize_simulation</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>(4,)
</code></pre></div>

<p>And then we can visualize simulation outputs and the observation:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sbi.analysis</span><span class="w"> </span><span class="kn">import</span> <span class="n">pairplot</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span>
    <span class="n">samples</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
    <span class="n">points</span><span class="o">=</span><span class="n">x_obs</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:],</span>  <span class="c1"># `points` needs a batch dimension.</span>
    <span class="n">limits</span><span class="o">=</span><span class="p">[[</span><span class="mi">40</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">]],</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
<span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
</code></pre></div>

<p><img alt="png" src="../01_Bayesian_workflow_files/01_Bayesian_workflow_23_1.png" /></p>
<p>Notice two things:
- First, the simulations (blue histogram) roughly cover the observation (orange line). This is a good sign. If the observation is far outside of the simulations, <code>sbi</code> will likely fail. Change your prior or simulator.
- Second, there are no extreme outliers in the simulation data. Remember that we will train a neural network on simulated data. If there are extreme outliers, this might lead to poor neural network convergence. For NPE, outliers can be safely ignored (i.e. removed from the dataset).  </p>
<h2 id="setting-up-the-neural-network">Setting up the neural network<a class="headerlink" href="#setting-up-the-neural-network" title="Permanent link">&para;</a></h2>
<p>We now want to set up a neural network for this example. For this example, we will use Neural Posterior Estimation (NPE) with a neural spline flow (<code>nsf</code>) as density estimator. See <a href="https://sbi.readthedocs.io/en/latest/sbi.html#neural-nets">here</a> for the collection of neural networks and <a href="https://sbi.readthedocs.io/en/latest/how_to_guide/03_choose_neural_net.html">here</a> for a guide on which methods to choose.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sbi.inference</span><span class="w"> </span><span class="kn">import</span> <span class="n">NPE</span>

<span class="n">inference</span> <span class="o">=</span> <span class="n">NPE</span><span class="p">(</span><span class="n">density_estimator</span><span class="o">=</span><span class="s2">&quot;nsf&quot;</span><span class="p">)</span>
</code></pre></div>
<p>We then train the network on our simulations:</p>
<div class="highlight"><pre><span></span><code><span class="n">posterior_net</span> <span class="o">=</span> <span class="n">inference</span><span class="o">.</span><span class="n">append_simulations</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code> Neural network successfully converged after 251 epochs.
</code></pre></div>

<p>We can check the convergence of the training loop by inspecting its loss curve:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sbi.analysis</span><span class="w"> </span><span class="kn">import</span> <span class="n">plot_summary</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">plot_summary</span><span class="p">(</span>
    <span class="n">inference</span><span class="p">,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;training_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;validation_loss&quot;</span><span class="p">],</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="p">)</span>
<span class="c1"># All training logs are available in `trainer.summary`.</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>For an interactive, detailed view of the summary, launch tensorboard  with &#39;tensorboard --logdir=/Users/michaeldeistler/Documents/phd/sbi/docs/tutorials/sbi-logs/NPE_C/2025-03-27T08_04_09.315358&#39; from a terminal on your machine, visit http://127.0.0.1:6006 afterwards. Requires port forwarding if tensorboard runs on a remote machine, as e.g. https://stackoverflow.com/a/42445070/7770835 explains.

Valid tags are: [&#39;best_validation_loss&#39;, &#39;epoch_durations_sec&#39;, &#39;epochs_trained&#39;, &#39;training_loss&#39;, &#39;validation_loss&#39;].
</code></pre></div>

<p><img alt="png" src="../01_Bayesian_workflow_files/01_Bayesian_workflow_31_1.png" /></p>
<p>In this case, the validation loss seems to still be going down, so it might be worth setting a higher value for <code>.train(stop_after_epochs=30)</code> (default value is 20). This parameter sets how many epochs must pass for without the validation loss reaching a new minimum. For this example, we will not retrain.</p>
<p>After training, we can build the <code>posterior</code>:</p>
<div class="highlight"><pre><span></span><code><span class="n">posterior</span> <span class="o">=</span> <span class="n">inference</span><span class="o">.</span><span class="n">build_posterior</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Posterior p(Î¸|x) of type DirectPosterior. It samples the posterior network and rejects samples that
            lie outside of the prior bounds.
</code></pre></div>

<blockquote>
<p>For NPE, the <code>posterior</code> and the <code>posterior_net</code> are almost identical. The <code>posterior_estimator</code> merely includes convenience functionality. For example, it automatically rejects samples outside of the prior support, or it can compute the maximum-a-posteriori estimate with <code>.map()</code></p>
</blockquote>
<h2 id="inferring-the-posterior">Inferring the posterior<a class="headerlink" href="#inferring-the-posterior" title="Permanent link">&para;</a></h2>
<p>Let&rsquo;s aim to infer the posterior given our observation:</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Observation: &quot;</span><span class="p">,</span> <span class="n">x_obs</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Observation:  [50.2497606  24.65478002  9.52736287  6.05178971]
</code></pre></div>

<p>We can sample from the NPE-posterior:</p>
<div class="highlight"><pre><span></span><code><span class="n">samples</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">1_000</span><span class="p">,),</span> <span class="n">x</span><span class="o">=</span><span class="n">x_obs</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Drawing 1000 posterior samples for 1 observations:   0%|          | 0/1000 [00:00&lt;?, ?it/s]


/Users/michaeldeistler/anaconda3/envs/sbi/lib/python3.12/site-packages/nflows/transforms/lu.py:80: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.
torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.
X = torch.triangular_solve(B, A).solution
should be replaced with
X = torch.linalg.solve_triangular(A, B). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2196.)
  outputs, _ = torch.triangular_solve(
</code></pre></div>

<blockquote>
<p>Again, you can infer the posterior distribution for any observation <span class="arithmatex">\(x_{obs}\)</span> without having to run new simulations and without having to re-train (amortization).</p>
</blockquote>
<h2 id="visualizing-the-posterior">Visualizing the posterior<a class="headerlink" href="#visualizing-the-posterior" title="Permanent link">&para;</a></h2>
<p>Next, we visualize these posterior samples with the <code>pairplot</code> function:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sbi.analysis</span><span class="w"> </span><span class="kn">import</span> <span class="n">pairplot</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">pairplot</span><span class="p">(</span>
    <span class="n">samples</span><span class="p">,</span>
    <span class="n">limits</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]],</span>
    <span class="n">ticks</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]],</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="sa">r</span><span class="s2">&quot;$\alpha$&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\beta$&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\delta$&quot;</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$\gamma$&quot;</span><span class="p">]</span>
<span class="p">)</span>
</code></pre></div>
<p><img alt="png" src="../01_Bayesian_workflow_files/01_Bayesian_workflow_43_0.png" /></p>
<h2 id="diagnosing-potential-issues-in-the-posterior">Diagnosing potential issues in the posterior<a class="headerlink" href="#diagnosing-potential-issues-in-the-posterior" title="Permanent link">&para;</a></h2>
<p>How do we know that the posterior is correct? The <code>sbi</code> toolbox implements a wide range
of methods that diagnose potential issues (more detail in <a href="https://sbi.readthedocs.io/en/latest/how_to_guide/14_choose_diagnostic_tool.html">this how-to guide</a>). In this tutorial, we will perform <em>posterior predictive checks</em> (PPC) and we will perform <em>simulation-based calibration</em> (SBC).</p>
<h3 id="posterior-predictive-checks">Posterior predictive checks<a class="headerlink" href="#posterior-predictive-checks" title="Permanent link">&para;</a></h3>
<p>Let&rsquo;s first perform posterior predictive checks. For these, we simulate posterior samples and compare them to the observation.</p>
<div class="highlight"><pre><span></span><code><span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">10</span><span class="p">,),</span> <span class="n">x</span><span class="o">=</span><span class="n">x_obs</span><span class="p">)</span>
<span class="n">posterior_predictives</span> <span class="o">=</span> <span class="n">parallel_simulate</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">)</span>

<span class="n">posterior_predictive_summary_stats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">summarize_simulation</span><span class="p">(</span><span class="n">sim</span><span class="p">)</span> <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">simulation_outputs</span><span class="p">]),</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
<span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Drawing 10 posterior samples for 1 observations:   0%|          | 0/10 [00:00&lt;?, ?it/s]
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_vec</span><span class="p">,</span> <span class="n">observation</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_vec</span><span class="p">,</span> <span class="n">observation</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_vec</span><span class="p">,</span> <span class="n">posterior_predictives</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_vec</span><span class="p">,</span> <span class="n">posterior_predictives</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Prey&quot;</span><span class="p">,</span> <span class="s2">&quot;Predator&quot;</span><span class="p">])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Population&quot;</span><span class="p">)</span>
</code></pre></div>
<p><img alt="png" src="../01_Bayesian_workflow_files/01_Bayesian_workflow_48_0.png" /></p>
<p>As you can see, the posterior predictives (light blue and light orange) look similar to the observation (blue and orange). They do not look exactly the same, but this is expected: we only used the maximum and mean of the two traces as summary statistic. If you want a closer fit, define more summary statistics, or <a href="https://sbi.readthedocs.io/en/latest/how_to_guide/04_embedding_networks.html">use the full time series with an embedding network</a>.</p>
<h3 id="simulation-based-calibration">Simulation-based calibration<a class="headerlink" href="#simulation-based-calibration" title="Permanent link">&para;</a></h3>
<p>Posterior-predictive checks are an ad-hoc heuristic for assessing posterior quality. Simulation-based calibration (SBC) provides a <em>quantitative</em> assessment of posterior quality. It allows you to check, for every parameter, whether the parameter is estimated as (on average) to low, to high, and whether it has too low or two high uncertainty. To run SBC, you first have to generate more simulations based on prior samples:</p>
<div class="highlight"><pre><span></span><code><span class="n">num_sbc_samples</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># choose a number of sbc runs, should be ~100s</span>

<span class="n">prior_samples</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">num_sbc_samples</span><span class="p">,))</span>

<span class="n">prior_predictives</span> <span class="o">=</span> <span class="n">parallel_simulate</span><span class="p">(</span><span class="n">prior_samples</span><span class="p">)</span>
<span class="n">prior_predictive_summary_stats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">summarize_simulation</span><span class="p">(</span><span class="n">sim</span><span class="p">)</span> <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">prior_predictives</span><span class="p">]),</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
<span class="p">)</span>
</code></pre></div>
<p>SBC is implemented in <code>sbi</code> for your use on any <code>sbi</code> posterior. To run it, we only need to call <code>run_sbc</code> with appropriate parameters.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sbi.diagnostics</span><span class="w"> </span><span class="kn">import</span> <span class="n">run_sbc</span>

<span class="c1"># run SBC: for each inference we draw 1000 posterior samples.</span>
<span class="n">num_posterior_samples</span> <span class="o">=</span> <span class="mi">1_000</span>
<span class="n">ranks</span><span class="p">,</span> <span class="n">dap_samples</span> <span class="o">=</span> <span class="n">run_sbc</span><span class="p">(</span>
    <span class="n">prior_samples</span><span class="p">,</span>
    <span class="n">prior_predictive_summary_stats</span><span class="p">,</span>
    <span class="n">posterior</span><span class="p">,</span>
    <span class="n">reduce_fns</span><span class="o">=</span><span class="k">lambda</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">posterior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span>
    <span class="n">num_posterior_samples</span><span class="o">=</span><span class="n">num_posterior_samples</span><span class="p">,</span>
    <span class="n">use_batched_sampling</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># `True` can give speed-ups, but can cause memory issues.</span>
<span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Sampling 200 times (1000,) posterior samples.: 100%|ââââââââââââââââââââ| 200/200 [00:01&lt;00:00, 122.30it/s]



Calculating ranks for 200 sbc samples.:   0%|          | 0/200 [00:00&lt;?, ?it/s]
</code></pre></div>

<blockquote>
<p>For amortized neural posteriors (like in this tutorial), execution of <code>sbc</code> is expected to be fast. For posteriors that conduct inference with MCMC and hence are slow, <code>run_sbc</code> exposes the use of multiple internal parallel workers to the user. To use this feature, add <code>num_workers = 2</code> to the parameters for use of two workers. See the API documentation for details.</p>
</blockquote>
<p>If the posterior approximation is faithful, the <code>ranks</code> should be uniformly distributed. We can evaluate this with by plotting a histogram of the resulting ranks:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sbi.analysis.plot</span><span class="w"> </span><span class="kn">import</span> <span class="n">sbc_rank_plot</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">sbc_rank_plot</span><span class="p">(</span>
    <span class="n">ranks</span><span class="p">,</span>
    <span class="n">num_posterior_samples</span><span class="p">,</span>
    <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;cdf&quot;</span><span class="p">,</span>
    <span class="n">num_bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
<span class="p">)</span>
</code></pre></div>
<p><img alt="png" src="../01_Bayesian_workflow_files/01_Bayesian_workflow_57_0.png" /></p>
<p>The gray are marks the region which is still sufficiently uniform (meaning that we cannot reject the null hypothesis that the samples are uniform). In this case, all ranks (in red) are within this gray band. This is a good sign, but it is only a necessary&mdash;but not a sufficient&mdash;condition for the posterior to be correct. To this end, <code>sbi</code> implements a wide range of diagnostic methods, which are described <a href="https://sbi.readthedocs.io/en/latest/how_to_guide/14_choose_diagnostic_tool.html">here</a>.</p>
<h2 id="next-steps">Next steps<a class="headerlink" href="#next-steps" title="Permanent link">&para;</a></h2>
<p>Next, we recommend that you check our <a href="https://sbi.readthedocs.io/en/latest/how_to_guide.html">how-to guide</a> for brief tutorials on specific features, our <a href="https://sbi.readthedocs.io/en/latest/advanced_tutorials.html">advanced tutorials</a> for detailed explanations, or our <a href="https://sbi.readthedocs.io/en/latest/sbi.html">API reference</a>, which provides a complete list of all features in the <code>sbi</code> toolbox.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/sbi-dev/sbi" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M202.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M496 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.92b07e13.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>