{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sbi.neural_nets.estimators import MixedDensityEstimator\n",
    "from sbi.neural_nets.estimators.categorical_net import CategoricalMADE, CategoricalMassEstimator\n",
    "from sbi.utils.torchutils import BoxUniform\n",
    "import matplotlib.pyplot as plt\n",
    "from sbi.inference import MNLE\n",
    "from sbi.neural_nets.estimators.nflows_flow import NFlowsFlow\n",
    "from sbi.neural_nets.net_builders.mdn import build_mdn\n",
    "from sbi.neural_nets.net_builders.categorial import build_autoregressive_categoricalmassestimator, build_categoricalmassestimator\n",
    "from sbi.neural_nets.net_builders.mnle import build_mnle\n",
    "from sbi.analysis import pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_simulator(theta: torch.Tensor, centers: list[torch.Tensor]) -> torch.Tensor:\n",
    "    batch_size, n_dimensions = theta.shape\n",
    "    assert len(centers) == n_dimensions, \"Number of center sets must match theta dimensions\"\n",
    "    \n",
    "    # Calculate discrete classes by assiging to the closest center\n",
    "    x_disc = torch.stack([\n",
    "        torch.argmin(torch.abs(centers[i].unsqueeze(1) - theta[:, i].unsqueeze(0)), dim=0)\n",
    "        for i in range(n_dimensions)\n",
    "    ], dim=1)\n",
    "\n",
    "    closest_centers = torch.stack([centers[i][x_disc[:, i]] for i in range(n_dimensions)], dim=1)\n",
    "    # Add Gaussian noise to assigned class centers\n",
    "    std = 0.4\n",
    "    x_cont = closest_centers + std * torch.randn_like(closest_centers)\n",
    "       \n",
    "    return torch.cat([x_cont, x_disc], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_706796/1950430755.py:17: UserWarning: Inferring categories from batch_x. Ensure all categories are present.\n",
      "  cmade = build_autoregressive_categoricalmassestimator(x[:,-len(centers):], theta)\n",
      "/tmp/ipykernel_706796/1950430755.py:19: UserWarning: The mixed neural likelihood estimator assumes that x contains continuous data in the first n-k columns (e.g., reaction times) and categorical data in the last k columns (e.g., corresponding choices). If this is not the case for the passed `x` do not use this function.\n",
      "  cmade_mnle = build_mnle(x, theta, categorical_model=\"made\")\n",
      "/tmp/ipykernel_706796/1950430755.py:28: UserWarning: The mixed neural likelihood estimator assumes that x contains continuous data in the first n-k columns (e.g., reaction times) and categorical data in the last k columns (e.g., corresponding choices). If this is not the case for the passed `x` do not use this function.\n",
      "  trainer = MNLE(density_estimator=lambda x,y: build_mnle(y,x,categorical_model=\"made\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 20 epochs."
     ]
    }
   ],
   "source": [
    "# THIS WORKS FOR 1D\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "centers = [\n",
    "    torch.tensor([-0.5, 0.5]),\n",
    "    # torch.tensor([-1.0, 0.0, 1.0]),\n",
    "]\n",
    "\n",
    "prior = BoxUniform(low=torch.tensor([-2.0]*len(centers)), high=torch.tensor([2.0]*len(centers)))\n",
    "theta = prior.sample((10000,))\n",
    "x = toy_simulator(theta, centers)\n",
    "theta = torch.hstack([theta, torch.randn_like(theta)])\n",
    "\n",
    "theta_o = prior.sample((1,))\n",
    "x_o = toy_simulator(theta_o, centers)\n",
    "\n",
    "cmade = build_autoregressive_categoricalmassestimator(x[:,-len(centers):], theta)\n",
    "mlp = build_categoricalmassestimator(x[:,-len(centers):], theta)\n",
    "cmade_mnle = build_mnle(x, theta, categorical_model=\"made\")\n",
    "\n",
    "# MNLE mixes up x,y (input and condition data!)\n",
    "# Train MNLE and obtain MCMC-based posterior.\n",
    "trainer = MNLE(density_estimator=lambda x,y: build_mnle(y,x,categorical_model=\"made\"))\n",
    "estimator = trainer.append_simulations(theta, x).train(training_batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import SNPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_706796/1968649956.py:16: UserWarning: Inferring categories from batch_x. Ensure all categories are present.\n",
      "  cmade = build_autoregressive_categoricalmassestimator(x[:,-len(centers):], theta)\n",
      "/tmp/ipykernel_706796/1968649956.py:17: UserWarning: The mixed neural likelihood estimator assumes that x contains continuous data in the first n-k columns (e.g., reaction times) and categorical data in the last k columns (e.g., corresponding choices). If this is not the case for the passed `x` do not use this function.\n",
      "  cmade_mnle = build_mnle(x, theta, categorical_model=\"made\")\n",
      "/home/jnsbck/Uni/PhD/projects/sbi_hackathon/sbi_fork/sbi/neural_nets/net_builders/mnle.py:155: UserWarning: Inferring categories from batch_x. Ensure all categories are present.\n",
      "  discrete_net = build_autoregressive_categoricalmassestimator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 117"
     ]
    }
   ],
   "source": [
    "# THIS WORKS FOR 2D\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "centers = [\n",
    "    torch.tensor([-0.5, 0.5]),\n",
    "    torch.tensor([-1.0, 0.0, 1.0]),\n",
    "]\n",
    "\n",
    "prior = BoxUniform(low=torch.tensor([-2.0]*len(centers)), high=torch.tensor([2.0]*len(centers)))\n",
    "theta = prior.sample((20000,))\n",
    "x = toy_simulator(theta, centers)\n",
    "\n",
    "theta_o = prior.sample((1,))\n",
    "x_o = toy_simulator(theta_o, centers)\n",
    "\n",
    "cmade = build_autoregressive_categoricalmassestimator(x[:,-len(centers):], theta)\n",
    "cmade_mnle = build_mnle(x, theta, categorical_model=\"made\")\n",
    "\n",
    "# Train MNLE and obtain MCMC-based posterior.\n",
    "# trainer = MNLE(density_estimator=lambda x,y: build_mnle(y,x,categorical_model=\"made\"))\n",
    "trainer = SNPE()\n",
    "estimator = trainer.append_simulations(theta=theta, x=x).train(training_batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snpe_posterior = trainer.build_posterior(prior=prior)\n",
    "posterior_samples = snpe_posterior.sample((2000,), x=x_o)\n",
    "pairplot(posterior_samples, limits=[[-2, 2], [-2, 2]], figsize=(5, 5), points=theta_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5cc867b10d4548aa39a703c08bdf0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running vectorized MCMC with 20 chains:   0%|          | 0/12000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m theta_o \u001b[38;5;241m=\u001b[39m prior\u001b[38;5;241m.\u001b[39msample((\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m     14\u001b[0m x_o \u001b[38;5;241m=\u001b[39m toy_simulator(theta_o, centers)\n\u001b[0;32m---> 16\u001b[0m mnle_samples \u001b[38;5;241m=\u001b[39m \u001b[43mmnle_posterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_o\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmcmc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Uni/PhD/projects/sbi_hackathon/sbi_fork/sbi/inference/posteriors/mcmc_posterior.py:318\u001b[0m, in \u001b[0;36mMCMCPosterior.sample\u001b[0;34m(self, sample_shape, x, method, thin, warmup_steps, num_chains, init_strategy, init_strategy_parameters, init_strategy_num_candidates, mcmc_parameters, mcmc_method, sample_with, num_workers, mp_context, show_progress_bars)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(track_gradients):\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice_np\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice_np_vectorized\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 318\u001b[0m         transformed_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_np_mcmc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpotential_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpotential_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m            \u001b[49m\u001b[43mthin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    323\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvectorized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslice_np_vectorized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m            \u001b[49m\u001b[43minterchangeable_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshow_progress_bars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhmc_pyro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnuts_pyro\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    330\u001b[0m         transformed_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pyro_mcmc(\n\u001b[1;32m    331\u001b[0m             num_samples\u001b[38;5;241m=\u001b[39mnum_samples,\n\u001b[1;32m    332\u001b[0m             potential_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpotential_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m             mp_context\u001b[38;5;241m=\u001b[39mmp_context,\n\u001b[1;32m    340\u001b[0m         )\n",
      "File \u001b[0;32m~/Uni/PhD/projects/sbi_hackathon/sbi_fork/sbi/inference/posteriors/mcmc_posterior.py:753\u001b[0m, in \u001b[0;36mMCMCPosterior._slice_np_mcmc\u001b[0;34m(self, num_samples, potential_function, initial_params, thin, warmup_steps, vectorized, interchangeable_chains, num_workers, init_width, show_progress_bars)\u001b[0m\n\u001b[1;32m    751\u001b[0m num_samples_ \u001b[38;5;241m=\u001b[39m ceil((num_samples \u001b[38;5;241m*\u001b[39m thin) \u001b[38;5;241m/\u001b[39m num_chains)\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# Run mcmc including warmup\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mposterior_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwarmup_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_samples_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m samples \u001b[38;5;241m=\u001b[39m samples[:, warmup_steps:, :]  \u001b[38;5;66;03m# discard warmup steps\u001b[39;00m\n\u001b[1;32m    755\u001b[0m samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(samples)  \u001b[38;5;66;03m# chains x samples x dim\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/PhD/projects/sbi_hackathon/sbi_fork/sbi/samplers/mcmc/slice_numpy.py:462\u001b[0m, in \u001b[0;36mSliceSamplerVectorized.run\u001b[0;34m(self, num_samples)\u001b[0m\n\u001b[1;32m    455\u001b[0m         sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_param\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\n\u001b[1;32m    456\u001b[0m             sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m][: sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m\"\u001b[39m][sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m]]],\n\u001b[1;32m    457\u001b[0m             [sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcxi\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m    458\u001b[0m             sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m][sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m\"\u001b[39m][sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :],\n\u001b[1;32m    459\u001b[0m         ])\n\u001b[1;32m    461\u001b[0m params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([sc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_param\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mvalues()])\n\u001b[0;32m--> 462\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_chains):\n\u001b[1;32m    465\u001b[0m     sc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[c]\n",
      "File \u001b[0;32m~/Uni/PhD/projects/sbi_hackathon/sbi_fork/sbi/inference/posteriors/mcmc_posterior.py:738\u001b[0m, in \u001b[0;36mMCMCPosterior._slice_np_mcmc.<locals>.multi_obs_potential\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmulti_obs_potential\u001b[39m(params):\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;66;03m# Params are of shape (num_chains * num_obs, event).\u001b[39;00m\n\u001b[0;32m--> 738\u001b[0m     all_potentials \u001b[38;5;241m=\u001b[39m \u001b[43mpotential_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (num_chains, num_obs)\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_potentials\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/Uni/PhD/projects/sbi_hackathon/sbi_fork/sbi/utils/potentialutils.py:44\u001b[0m, in \u001b[0;36mtransformed_potential\u001b[0;34m(theta, potential_fn, theta_transform, device, track_gradients)\u001b[0m\n\u001b[1;32m     41\u001b[0m theta \u001b[38;5;241m=\u001b[39m theta_transform\u001b[38;5;241m.\u001b[39minv(transformed_theta)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     42\u001b[0m log_abs_det \u001b[38;5;241m=\u001b[39m theta_transform\u001b[38;5;241m.\u001b[39mlog_abs_det_jacobian(theta, transformed_theta)\n\u001b[0;32m---> 44\u001b[0m posterior_potential \u001b[38;5;241m=\u001b[39m \u001b[43mpotential_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m posterior_potential_transformed \u001b[38;5;241m=\u001b[39m posterior_potential \u001b[38;5;241m-\u001b[39m log_abs_det\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m posterior_potential_transformed\n",
      "File \u001b[0;32m~/Uni/PhD/projects/sbi_hackathon/sbi_fork/sbi/inference/potentials/likelihood_based_potential.py:95\u001b[0m, in \u001b[0;36mLikelihoodBasedPotential.__call__\u001b[0;34m(self, theta, track_gradients)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the potential $\\log(p(x_o|\\theta)p(\\theta))$.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    The potential $\\log(p(x_o|\\theta)p(\\theta))$.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_is_iid:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# For each theta, calculate the likelihood sum over all x in batch.\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     log_likelihood_trial_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_log_likelihoods_over_trials\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_o\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrack_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_likelihood_trial_sum \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39mlog_prob(theta)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Calculate likelihood for each (theta,x) pair separately\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/PhD/projects/sbi_hackathon/sbi_fork/sbi/inference/potentials/likelihood_based_potential.py:168\u001b[0m, in \u001b[0;36m_log_likelihoods_over_trials\u001b[0;34m(x, theta, estimator, track_gradients)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Calculate likelihood in one batch.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(track_gradients):\n\u001b[0;32m--> 168\u001b[0m     log_likelihood_trial_batch \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Sum over trial-log likelihoods.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     log_likelihood_trial_sum \u001b[38;5;241m=\u001b[39m log_likelihood_trial_batch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Uni/PhD/projects/sbi_hackathon/sbi_fork/sbi/neural_nets/estimators/nflows_flow.py:109\u001b[0m, in \u001b[0;36mNFlowsFlow.log_prob\u001b[0;34m(self, input, condition)\u001b[0m\n\u001b[1;32m    106\u001b[0m ones_for_event_dims \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m condition_event_dims  \u001b[38;5;66;03m# Tuple of 1s, e.g. (1, 1, 1)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m condition \u001b[38;5;241m=\u001b[39m condition\u001b[38;5;241m.\u001b[39mrepeat(input_sample_dim, \u001b[38;5;241m*\u001b[39mones_for_event_dims)\n\u001b[0;32m--> 109\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_probs\u001b[38;5;241m.\u001b[39mreshape((input_sample_dim, input_batch_dim))\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/sbi/lib/python3.10/site-packages/nflows/distributions/base.py:40\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m context\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of input items must be equal to number of context items.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/sbi/lib/python3.10/site-packages/nflows/flows/base.py:39\u001b[0m, in \u001b[0;36mFlow._log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context):\n\u001b[1;32m     38\u001b[0m     embedded_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_net(context)\n\u001b[0;32m---> 39\u001b[0m     noise, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedded_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution\u001b[38;5;241m.\u001b[39mlog_prob(noise, context\u001b[38;5;241m=\u001b[39membedded_context)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob \u001b[38;5;241m+\u001b[39m logabsdet\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/sbi/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/sbi/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/sbi/lib/python3.10/site-packages/nflows/transforms/base.py:56\u001b[0m, in \u001b[0;36mCompositeTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     55\u001b[0m     funcs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transforms\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cascade\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuncs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/sbi/lib/python3.10/site-packages/nflows/transforms/base.py:50\u001b[0m, in \u001b[0;36mCompositeTransform._cascade\u001b[0;34m(inputs, funcs, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m total_logabsdet \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mnew_zeros(batch_size)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m---> 50\u001b[0m     outputs, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     total_logabsdet \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m logabsdet\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, total_logabsdet\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/sbi/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/sbi/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/sbi/lib/python3.10/site-packages/nflows/transforms/autoregressive.py:39\u001b[0m, in \u001b[0;36mAutoregressiveTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     38\u001b[0m     autoregressive_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive_net(inputs, context)\n\u001b[0;32m---> 39\u001b[0m     outputs, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_elementwise_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoregressive_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs, logabsdet\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/sbi/lib/python3.10/site-packages/nflows/transforms/autoregressive.py:96\u001b[0m, in \u001b[0;36mMaskedAffineAutoregressiveTransform._elementwise_forward\u001b[0;34m(self, inputs, autoregressive_params)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_elementwise_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, autoregressive_params):\n\u001b[0;32m---> 96\u001b[0m     unconstrained_scale, shift \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unconstrained_scale_and_shift\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoregressive_params\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# scale = torch.sigmoid(unconstrained_scale + 2.0) + self._epsilon\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     scale \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftplus(unconstrained_scale) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epsilon\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mcmc_kwargs = dict(\n",
    "    num_chains=20,\n",
    "    warmup_steps=50,\n",
    "    method=\"slice_np_vectorized\",\n",
    "    init_strategy=\"proposal\",\n",
    ")\n",
    "\n",
    "# Build posterior from the trained estimator and prior.\n",
    "mnle_posterior = trainer.build_posterior(prior=prior)\n",
    "\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "theta_o = prior.sample((1,))\n",
    "x_o = toy_simulator(theta_o, centers)\n",
    "\n",
    "mnle_samples = mnle_posterior.sample((10000,), x=x_o, **mcmc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 500x500 with 4 Axes>,\n",
       " array([[<Axes: xlabel='dim 1'>, <Axes: >],\n",
       "        [<Axes: xlabel='dim 1'>, <Axes: xlabel='dim 2'>]], dtype=object))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairplot(mnle_samples, limits=[[-2, 2], [-2, 2]], figsize=(5, 5), points=theta_o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
