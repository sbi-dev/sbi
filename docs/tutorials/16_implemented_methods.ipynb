{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd7f17d",
   "metadata": {},
   "source": [
    "# API of implemented methods\n",
    "\n",
    "This notebook spells out the API for all algorithms implemented in the `sbi` toolbox:\n",
    "\n",
    "- Posterior estimation (NPE)\n",
    "\n",
    "- Likelihood estimation (NLE)\n",
    "\n",
    "- Likelihood-ratio estimation (NRE)\n",
    "\n",
    "- Utilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e608393",
   "metadata": {},
   "source": [
    "## Posterior estimation (NPE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4bc6b4",
   "metadata": {},
   "source": [
    "**Fast ε-free Inference of Simulation Models with Bayesian Conditional Density Estimation**<br> by Papamakarios & Murray (NeurIPS 2016) <br>[[PDF]](https://papers.nips.cc/paper/6084-fast-free-inference-of-simulation-models-with-bayesian-conditional-density-estimation.pdf) [[BibTeX]](https://papers.nips.cc/paper/6084-fast-free-inference-of-simulation-models-with-bayesian-conditional-density-estimation/bibtex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3893ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example setup\n",
    "import torch\n",
    "\n",
    "from sbi.utils import BoxUniform\n",
    "\n",
    "# Define the prior\n",
    "num_dims = 2\n",
    "num_sims = 1000\n",
    "num_rounds = 2\n",
    "prior = BoxUniform(low=torch.zeros(num_dims), high=torch.ones(num_dims))\n",
    "simulator = lambda theta: theta + torch.randn_like(theta) * 0.1\n",
    "x_o = torch.tensor([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c2e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import NPE_A\n",
    "\n",
    "inference = NPE_A(prior)\n",
    "proposal = prior\n",
    "for r in range(num_rounds):\n",
    "    theta = proposal.sample((num_sims,))\n",
    "    x = simulator(theta)\n",
    "    # NPE-A trains a Gaussian density estimator in all but the last round. In the last round,\n",
    "    # it trains a mixture of Gaussians, which is why we have to pass the `final_round` flag.\n",
    "    final_round = r == num_rounds - 1\n",
    "    _ = inference.append_simulations(theta, x, proposal=proposal).train(final_round=final_round)\n",
    "    posterior = inference.build_posterior().set_default_x(x_o)\n",
    "    proposal = posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddd7f43",
   "metadata": {},
   "source": [
    "**Automatic posterior transformation for likelihood-free inference**<br>by Greenberg, Nonnenmacher & Macke (ICML 2019) <br>[[PDF]](http://proceedings.mlr.press/v97/greenberg19a/greenberg19a.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d8514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import NPE\n",
    "\n",
    "inference = NPE(prior)\n",
    "proposal = prior\n",
    "for _ in range(num_rounds):\n",
    "    theta = proposal.sample((num_sims,))\n",
    "    x = simulator(theta)\n",
    "    _ = inference.append_simulations(theta, x, proposal=proposal).train()\n",
    "    posterior = inference.build_posterior().set_default_x(x_o)\n",
    "    proposal = posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc71c3a1",
   "metadata": {},
   "source": [
    "**BayesFlow: Learning complex stochastic models with invertible neural\n",
    "networks**<br> by Radev, S. T., Mertens, U. K., Voss, A., Ardizzone, L., & Köthe,\n",
    "U. (2020) (IEEE transactions on neural networks and learning systems 2020)<br>\n",
    "[Paper](https://ieeexplore.ieee.org/abstract/document/9298920)\n",
    "\n",
    "The density estimation part of BayesFlow is equivalent to single-round NPE. The\n",
    "additional contribution of the paper are several embedding networks for high-dimensional\n",
    "data including permutation invariant embeddings. Similar embeddings networks are\n",
    "implemented in `sbi` as well, under `sbi.neural_nets.embedding_nets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd8641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior estimation with BayesFlow is equivalent to single-round NPE.\n",
    "from sbi.inference import NPE\n",
    "\n",
    "inference = NPE(prior)\n",
    "theta = prior.sample((num_sims,))\n",
    "x = simulator(theta)\n",
    "inference.append_simulations(theta, x).train()\n",
    "posterior = inference.build_posterior()\n",
    "samples = posterior.sample((1000,), x=x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef8b35",
   "metadata": {},
   "source": [
    "**Truncated proposals for scalable and hassle-free simulation-based inference** <br> by Deistler, Goncalves & Macke (NeurIPS 2022) <br>[[Paper]](https://arxiv.org/abs/2210.04815)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93183126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import NPE\n",
    "from sbi.utils import RestrictedPrior, get_density_thresholder\n",
    "\n",
    "inference = NPE(prior)\n",
    "proposal = prior\n",
    "for _ in range(num_rounds):\n",
    "    theta = proposal.sample((num_sims,))\n",
    "    x = simulator(theta)\n",
    "    _ = inference.append_simulations(theta, x).train(force_first_round_loss=True)\n",
    "    posterior = inference.build_posterior().set_default_x(x_o)\n",
    "\n",
    "    accept_reject_fn = get_density_thresholder(posterior, quantile=1e-4)\n",
    "    proposal = RestrictedPrior(prior, accept_reject_fn, sample_with=\"rejection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2ea8c",
   "metadata": {},
   "source": [
    "**Flow Matching for Scalable Simulation-Based Inference** <br> by Dax, Wildberger, Buchholz, Green, Macke,\n",
    "Schölkopf (NeurIPS 2023) <br> [[Paper]](https://arxiv.org/abs/2305.17161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import FMPE\n",
    "\n",
    "inference = FMPE(prior)\n",
    "# FMPE does not support multiple rounds of inference\n",
    "theta = prior.sample((num_sims,))\n",
    "x = simulator(theta)\n",
    "inference.append_simulations(theta, x).train()\n",
    "posterior = inference.build_posterior().set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7beab32",
   "metadata": {},
   "source": [
    "**Neural posterior score estimation**<br>\n",
    "\n",
    "based on:  \n",
    "\n",
    "- **Compositional Score Modeling for Simulation-based Inference** by Geffner, T., Papamakarios, G., & Mnih, A. (ICML 2023) [[Paper]](https://proceedings.mlr.press/v202/geffner23a.html)  \n",
    "- **Sequential Neural Score Estimation: Likelihood-Free Inference with Conditional Score Based Diffusion Models** by Sharrock, L., Simons, J., Liu, S., & Beaumont, M. (ICML 2024) [[Paper]](https://arxiv.org/abs/2210.04872)  \n",
    "\n",
    "Note that currently only the single-round variant is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b68242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import NPSE\n",
    "\n",
    "theta = prior.sample((num_sims,))\n",
    "x = simulator(theta)\n",
    "\n",
    "inference = NPSE(prior, sde_type=\"ve\")\n",
    "_ = inference.append_simulations(theta, x).train()\n",
    "posterior = inference.build_posterior().set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20cda82",
   "metadata": {},
   "source": [
    "## Likelihood estimation (NLE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90120ff8",
   "metadata": {},
   "source": [
    "**Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows**<br>by Papamakarios, Sterratt & Murray (AISTATS 2019) <br>[[PDF]](http://proceedings.mlr.press/v89/papamakarios19a/papamakarios19a.pdf) [[BibTeX]](https://gpapamak.github.io/bibtex/snl.bib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301098a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import NLE\n",
    "\n",
    "inference = NLE(prior)\n",
    "proposal = prior\n",
    "for _ in range(num_rounds):\n",
    "    theta = proposal.sample((num_sims,))\n",
    "    x = simulator(theta)\n",
    "    _ = inference.append_simulations(theta, x).train()\n",
    "    posterior = inference.build_posterior(mcmc_method=\"slice_np_vectorized\",\n",
    "                                          mcmc_parameters={\"num_chains\": 20,\n",
    "                                                           \"thin\": 5})\n",
    "    proposal = posterior.set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55404e7a",
   "metadata": {},
   "source": [
    "**Variational methods for simulation-based inference** <br> by Glöckler, Deistler, Macke (ICLR 2022) <br>[[Paper]](https://arxiv.org/abs/2203.04176)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f65ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import NLE\n",
    "\n",
    "inference = NLE(prior)\n",
    "proposal = prior\n",
    "for _ in range(num_rounds):\n",
    "    theta = proposal.sample((num_sims,))\n",
    "    x = simulator(theta)\n",
    "    _ = inference.append_simulations(theta, x).train()\n",
    "    posterior = inference.build_posterior(sample_with=\"vi\",\n",
    "                                          vi_method=\"fKL\").set_default_x(x_o)\n",
    "    proposal = posterior.train()  # Train VI posterior on given x_o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bfc57c",
   "metadata": {},
   "source": [
    "**Flexible and efficient simulation-based inference for models of decision-making** <br> by Boelts, Lueckmann, Gao, Macke (Elife 2022) <br>[[Paper]](https://elifesciences.org/articles/77220)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c674f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import MNLE\n",
    "\n",
    "inference = MNLE(prior)\n",
    "theta = prior.sample((num_sims,))\n",
    "# add a column of discrete data to x.\n",
    "x = torch.cat((simulator(theta), torch.bernoulli(theta[:, :1])), dim=1)\n",
    "_ = inference.append_simulations(theta, x).train()\n",
    "posterior = inference.build_posterior().set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d163f1",
   "metadata": {},
   "source": [
    "## Likelihood-ratio estimation (NRE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f830ef",
   "metadata": {},
   "source": [
    "**Likelihood-free MCMC with Amortized Approximate Likelihood Ratios**<br>by Hermans, Begy & Louppe (ICML 2020) <br>[[PDF]](http://proceedings.mlr.press/v119/hermans20a/hermans20a.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646642e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import NRE_A\n",
    "\n",
    "inference = NRE_A(prior)\n",
    "theta = prior.sample((num_sims,))\n",
    "x = simulator(theta)\n",
    "_ = inference.append_simulations(theta, x).train()\n",
    "posterior = inference.build_posterior().set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b1eb8",
   "metadata": {},
   "source": [
    "**On Contrastive Learning for Likelihood-free Inference**<br>Durkan, Murray & Papamakarios (ICML 2020) <br>[[PDF]](http://proceedings.mlr.press/v119/durkan20a/durkan20a.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import NRE\n",
    "\n",
    "inference = NRE(prior)\n",
    "proposal = prior\n",
    "for _ in range(num_rounds):\n",
    "    theta = proposal.sample((num_sims,))\n",
    "    x = simulator(theta)\n",
    "    _ = inference.append_simulations(theta, x).train()\n",
    "    posterior = inference.build_posterior(mcmc_method=\"slice_np_vectorized\",\n",
    "                                          mcmc_parameters={\"num_chains\": 20,\n",
    "                                                           \"thin\": 5})\n",
    "    proposal = posterior.set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53de3dd",
   "metadata": {},
   "source": [
    "**Towards Reliable Simulation-Based Inference with Balanced Neural Ratio Estimation**<br>by Delaunoy, Hermans, Rozet, Wehenkel & Louppe (NeurIPS 2022) <br>[[PDF]](https://arxiv.org/pdf/2208.13624.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577bf99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import BNRE\n",
    "\n",
    "inference = BNRE(prior)\n",
    "theta = prior.sample((num_sims,))\n",
    "x = simulator(theta)\n",
    "_ = inference.append_simulations(theta, x).train(regularization_strength=100.)\n",
    "posterior = inference.build_posterior().set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80922d50",
   "metadata": {},
   "source": [
    "**Contrastive Neural Ratio Estimation**<br>Benjamin Kurt Miller, Christoph Weniger, Patrick Forré (NeurIPS 2022) <br>[[PDF]](https://arxiv.org/pdf/2210.06170.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main feature of NRE-C is producing an exact ratio of densities at optimum,\n",
    "# even when using multiple contrastive pairs (classes).\n",
    "\n",
    "from sbi.inference import NRE_C\n",
    "\n",
    "inference = NRE_C(prior)\n",
    "proposal = prior\n",
    "theta = proposal.sample((num_sims,))\n",
    "x = simulator(theta)\n",
    "_ = inference.append_simulations(theta, x).train(\n",
    "    num_classes=5,  # sees `2 * num_classes - 1` marginally drawn contrastive pairs.\n",
    "    gamma=1.0,  # controls the weight between terms in its loss function.\n",
    ")\n",
    "posterior = inference.build_posterior().set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b5bace",
   "metadata": {},
   "source": [
    "## Diagnostics and utilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e501b8d",
   "metadata": {},
   "source": [
    "**Simulation-based calibration**<br>by Talts, Betancourt, Simpson, Vehtari, Gelman (arxiv 2018) <br>[[Paper]](https://arxiv.org/abs/1804.06788)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da329911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.analysis import sbc_rank_plot\n",
    "from sbi.diagnostics import run_sbc\n",
    "\n",
    "thetas = prior.sample((1000,))\n",
    "xs = simulator(thetas)\n",
    "\n",
    "# SBC is fast for fully amortized NPE.\n",
    "inference = NPE(prior)\n",
    "theta = prior.sample((num_sims,))\n",
    "x = simulator(theta)\n",
    "inference.append_simulations(theta, x).train()\n",
    "posterior = inference.build_posterior()\n",
    "\n",
    "ranks, dap_samples = run_sbc(\n",
    "    thetas, xs, posterior, num_posterior_samples=1_000\n",
    ")\n",
    "\n",
    "fig, axes = sbc_rank_plot(\n",
    "    ranks=ranks,\n",
    "    num_posterior_samples=1000,\n",
    "    plot_type=\"hist\",\n",
    "    num_bins=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720a391a",
   "metadata": {},
   "source": [
    "**Expected coverage (sample-based)**<br>as computed in Deistler, Goncalves, Macke (Neurips 2022) [[Paper]](https://arxiv.org/abs/2210.04815) and in Rozet, Louppe (2021) [[Paper]](https://matheo.uliege.be/handle/2268.2/12993)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6695d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = prior.sample((100,))\n",
    "xs = simulator(thetas)\n",
    "\n",
    "ranks, dap_samples = run_sbc(\n",
    "    thetas,\n",
    "    xs,\n",
    "    posterior,\n",
    "    num_posterior_samples=1_000,\n",
    "    reduce_fns=posterior.log_prob  # Difference to SBC.\n",
    ")\n",
    "\n",
    "# NOTE: Here we obtain a single rank plot because ranks are calculated\n",
    "# for the entire posterior and not for each marginal like in SBC.\n",
    "fig, axes = sbc_rank_plot(\n",
    "    ranks=ranks,\n",
    "    num_posterior_samples=1000,\n",
    "    plot_type=\"hist\",\n",
    "    num_bins=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d01a5b1",
   "metadata": {},
   "source": [
    "**TARP: Sampling-Based Accuracy Testing of Posterior Estimators for General Inference**\n",
    "\n",
    "Lemos, Coogan, Hezaveh & Perreault-Levasseur (ICML 2023)<br>[[Paper]](https://arxiv.org/abs/2302.03026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d79e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.analysis import plot_tarp\n",
    "from sbi.diagnostics.tarp import run_tarp\n",
    "\n",
    "thetas = prior.sample((1000,))\n",
    "xs = simulator(thetas)\n",
    "\n",
    "expected_coverage, ideal_coverage = run_tarp(\n",
    "    thetas,\n",
    "    xs,\n",
    "    posterior,\n",
    "    references=None,  # optional, defaults to uniform samples across parameter space.\n",
    "    num_posterior_samples=1_000,\n",
    ")\n",
    "\n",
    "fix, axes = plot_tarp(expected_coverage, ideal_coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dfeabc",
   "metadata": {},
   "source": [
    "**Restriction estimator**<br>by Deistler, Macke & Goncalves (PNAS 2022) <br>[[Paper]](https://www.pnas.org/doi/10.1073/pnas.2207632119)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import NPE\n",
    "from sbi.utils import RestrictionEstimator\n",
    "\n",
    "restriction_estimator = RestrictionEstimator(prior=prior)\n",
    "proposal = prior\n",
    "\n",
    "for _ in range(num_rounds):\n",
    "    theta = proposal.sample((num_sims,))\n",
    "    x = simulator(theta)\n",
    "    restriction_estimator.append_simulations(theta, x)\n",
    "    classifier = restriction_estimator.train()\n",
    "    proposal = restriction_estimator.restrict_prior()\n",
    "\n",
    "all_theta, all_x, _ = restriction_estimator.get_simulations()\n",
    "\n",
    "inference = NPE(prior)\n",
    "density_estimator = inference.append_simulations(all_theta, all_x).train()\n",
    "posterior = inference.build_posterior()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c50aa3a452b5e33eec699c3d0adceaddf116b15627c63bb6b43782d4547b8f5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
